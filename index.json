[{"categories":null,"contents":"","date":"May 15, 2025","hero":"/images/default-hero.jpg","permalink":"https://kubesy.com/posts/500.-tech_dev/%EA%B8%B0%ED%83%80/%EA%B8%B0%EC%88%A0-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EC%9C%A0%EC%A7%80%EB%B3%B4%EC%88%98/","summary":"","tags":null,"title":"방치해두었던 hugo 블로그 최신화 경험"},{"categories":null,"contents":"하루 일지 요약 기상 / 숙면 시간 어제는 12시 반쯤 잠들었다. 오늘은 7시 35분에 일어났다. 업무 및 공부 .. 오픈 스택 관련 글을 더 많이 써봐야겠다는 생각을 했다.(https://www.linkedin.com/posts/daewon-kim-80b1076b_%EC%B5%9C%EA%B7%BC%EC%97%90-%EC%A2%80-%EC%A7%88%EB%AC%B8%EC%9D%84-%EB%A7%8E%EC%9D%B4-%EC%A3%BC%EC%85%A8%EC%8A%B5%EB%8B%88%EB%8B%A4-%EC%98%A4%ED%94%88%EC%8A%A4%ED%83%9D-%EA%B5%90%EC%9C%A1%EC%9E%90%EB%A3%8C%EA%B0%80-%EC%9E%88%EB%82%98%EC%9A%94-activity-7328298813931061249-XDuS?utm_source=share\u0026utm_medium=member_desktop\u0026rcm=ACoAAEQdiIYBKymviVGUosvzr4p4D_brz1ikTyg) 이외의 생각 어두컴컴했어서 그런지 눈을 떴는데 원래 8시 출근 기준으로 일어나던 시간을 조금 넘긴 시간이었다. 국방의 의무에서 벗어난 몸이 된 기념으로 한 시간 더 잤다. 비가 와서 긴 팔을 입고 나갔다. ","date":"May 15, 2025","hero":"/images/default-hero.jpg","permalink":"https://kubesy.com/posts/100.-diary/2025-05-15/","summary":"\u003ch3 id=\"하루-일지-요약\"\u003e하루 일지 요약\u003c/h3\u003e\n\u003ch4 id=\"기상--숙면-시간\"\u003e기상 / 숙면 시간\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e어제는 12시 반쯤 잠들었다.\u003c/li\u003e\n\u003cli\u003e오늘은 7시 35분에 일어났다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"업무-및-공부-\"\u003e업무 및 공부 ..\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e오픈 스택 관련 글을 더 많이 써봐야겠다는 생각을 했다.(\u003ca href=\"https://www.linkedin.com/posts/daewon-kim-80b1076b_%EC%B5%9C%EA%B7%BC%EC%97%90-%EC%A2%80-%EC%A7%88%EB%AC%B8%EC%9D%84-%EB%A7%8E%EC%9D%B4-%EC%A3%BC%EC%85%A8%EC%8A%B5%EB%8B%88%EB%8B%A4-%EC%98%A4%ED%94%88%EC%8A%A4%ED%83%9D-%EA%B5%90%EC%9C%A1%EC%9E%90%EB%A3%8C%EA%B0%80-%EC%9E%88%EB%82%98%EC%9A%94-activity-7328298813931061249-XDuS?utm_source=share\u0026amp;utm_medium=member_desktop\u0026amp;rcm=ACoAAEQdiIYBKymviVGUosvzr4p4D_brz1ikTyg\" target=\"_blank\" rel=\"noopener\"\u003ehttps://www.linkedin.com/posts/daewon-kim-80b1076b_%EC%B5%9C%EA%B7%BC%EC%97%90-%EC%A2%80-%EC%A7%88%EB%AC%B8%EC%9D%84-%EB%A7%8E%EC%9D%B4-%EC%A3%BC%EC%85%A8%EC%8A%B5%EB%8B%88%EB%8B%A4-%EC%98%A4%ED%94%88%EC%8A%A4%ED%83%9D-%EA%B5%90%EC%9C%A1%EC%9E%90%EB%A3%8C%EA%B0%80-%EC%9E%88%EB%82%98%EC%9A%94-activity-7328298813931061249-XDuS?utm_source=share\u0026utm_medium=member_desktop\u0026rcm=ACoAAEQdiIYBKymviVGUosvzr4p4D_brz1ikTyg\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"이외의-생각\"\u003e이외의 생각\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e어두컴컴했어서 그런지 눈을 떴는데 원래 8시 출근 기준으로 일어나던 시간을 조금 넘긴 시간이었다. 국방의 의무에서 벗어난 몸이 된 기념으로 한 시간 더 잤다.\u003c/li\u003e\n\u003cli\u003e비가 와서 긴 팔을 입고 나갔다.\u003c/li\u003e\n\u003c/ul\u003e","tags":null,"title":"2025-05-15"},{"categories":null,"contents":"하루 일지 요약 매일매일 일지를 써야겠다는 생각을 가지게 되었다. 또 작심삼일이 될련지는 모르겠지만, 그래도 해보자.\n기상 / 숙면 시간 어제는 21시 쯤에 잠들었다. 오늘은 6시 50분에 일어났다. 업무 및 공부 .. 클라우드 네이티브를 위한 데이터센터 네트워크 구축 이라는 책을 읽고 있다. 4장 까지 읽었다. 과거의 네트워크 구성, 클로스(리프-스파인) 구조, NOS, OpenFlow 등 과거 어디선가 들어봤던, 하지만 흩어져 있던 개념들이 한 곳에 모이는 느낌이다. 큰 역사의 흐름을 알게 되니, 현재의 기술들이 왜 그렇게 발전했는지 알 수 있었고 그래서 좀 더 이해가 잘 되는 것 같았다. 예를 들어, STP 라는게 왜 필요했고, 지금은 왜 L3 기반 구조로 가는지 배울 수 있었다. 아직 좀 헷갈리긴 하지만. 기능 개발에 대한 프로세스에 대한 생각을 해봤다. 최근에 기존에 이미 개발되었던 코드를 도식화 하는 작업을 수행했는데, 새로 만드는 기능 건에 대해서 모두가 구조적 도식화를 수행하는 게 필수적이라는 생각을 했다. 이미 유지보수에 어려움을 겪고 있는 상황에서 과거의 코드들을 도식화 하는 것은 아무래도 무리겠지만 말이다. 그리고 전체 솔루션의 구조적 변경에는 강력한 힘을 가진 아키텍쳐 혹은 메인테이너가 존재해야 하지 않을까도 생각했다. 5월의 절반이 지나가는 시점에서도 아직 업무가 구체화되지 않았다. 내가 하고 싶은 일이 정확히 뭔지 점점 더 아리쏭해진다. Cilium을 통한 노드간 iBGP 통신에 성공하고 싶다. 다만 오늘 그쪽에 신경 쓸 여력이 없었다. Cilium Up\u0026amp;Running 이라는 책이 만들어지고 있다는 정보를 습득했다. 공룡책(운영체제) 책도 진행하지 못했다. 어쩌다보니 드문드문 손이 가게된다. 습관적으로 조금씩 읽어나가야 할텐데 말이다. 이외의 생각 더워진다. 반팔옷을 입어야겠다. 마음을 다잡아야 겠다. 요즘 너무 심란한 상태에 있었다. 보는 방향을 바꿔야겠다. 운동을 해야한다. 퇴근길은 되도록이면 걸어가자. 다만, 걸으면서 들을만한 좋은 팟캐스트가 있으면 좋겠다. 글쓰기에는 꾸준함이 필요하다. 미니서버 3대를 구성하고 싶다. 오픈스택 용 컨트롤러 + 컴퓨트 + 스토리지 구성으로 \u0026hellip; ","date":"May 14, 2025","hero":"/images/default-hero.jpg","permalink":"https://kubesy.com/posts/100.-diary/2025-05-14/","summary":"\u003ch3 id=\"하루-일지-요약\"\u003e하루 일지 요약\u003c/h3\u003e\n\u003cp\u003e매일매일 일지를 써야겠다는 생각을 가지게 되었다.\n또 작심삼일이 될련지는 모르겠지만, 그래도 해보자.\u003c/p\u003e\n\u003ch4 id=\"기상--숙면-시간\"\u003e기상 / 숙면 시간\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e어제는 21시 쯤에 잠들었다.\u003c/li\u003e\n\u003cli\u003e오늘은 6시 50분에 일어났다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"업무-및-공부-\"\u003e업무 및 공부 ..\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e클라우드 네이티브를 위한 데이터센터 네트워크 구축\u003c/strong\u003e 이라는 책을 읽고 있다. 4장 까지 읽었다.\n과거의 네트워크 구성, 클로스(리프-스파인) 구조, NOS, OpenFlow 등 과거 어디선가 들어봤던, 하지만 흩어져 있던 개념들이 한 곳에 모이는 느낌이다.\n큰 역사의 흐름을 알게 되니, 현재의 기술들이 왜 그렇게 발전했는지 알 수 있었고 그래서 좀 더 이해가 잘 되는 것 같았다.\n예를 들어, STP 라는게 왜 필요했고, 지금은 왜 L3 기반 구조로 가는지 배울 수 있었다. 아직 좀 헷갈리긴 하지만.\u003c/li\u003e\n\u003cli\u003e기능 개발에 대한 프로세스에 대한 생각을 해봤다. 최근에 기존에 이미 개발되었던 코드를 도식화 하는 작업을 수행했는데,\n새로 만드는 기능 건에 대해서 모두가 구조적 도식화를 수행하는 게 필수적이라는 생각을 했다. 이미 유지보수에 어려움을 겪고 있는 상황에서 과거의 코드들을 도식화 하는 것은 아무래도 무리겠지만 말이다. 그리고 전체 솔루션의 구조적 변경에는 강력한 힘을 가진 아키텍쳐 혹은 메인테이너가 존재해야 하지 않을까도 생각했다.\u003c/li\u003e\n\u003cli\u003e5월의 절반이 지나가는 시점에서도 아직 업무가 구체화되지 않았다. 내가 하고 싶은 일이 정확히 뭔지 점점 더 아리쏭해진다.\u003c/li\u003e\n\u003cli\u003eCilium을 통한 노드간 iBGP 통신에 성공하고 싶다. 다만 오늘 그쪽에 신경 쓸 여력이 없었다. Cilium Up\u0026amp;Running 이라는 책이 만들어지고 있다는 정보를 습득했다.\u003c/li\u003e\n\u003cli\u003e공룡책(운영체제) 책도 진행하지 못했다. 어쩌다보니 드문드문 손이 가게된다. 습관적으로 조금씩 읽어나가야 할텐데 말이다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"이외의-생각\"\u003e이외의 생각\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e더워진다. 반팔옷을 입어야겠다.\u003c/li\u003e\n\u003cli\u003e마음을 다잡아야 겠다. 요즘 너무 심란한 상태에 있었다. 보는 방향을 바꿔야겠다.\u003c/li\u003e\n\u003cli\u003e운동을 해야한다. 퇴근길은 되도록이면 걸어가자. 다만, 걸으면서 들을만한 좋은 팟캐스트가 있으면 좋겠다.\u003c/li\u003e\n\u003cli\u003e글쓰기에는 꾸준함이 필요하다.\u003c/li\u003e\n\u003cli\u003e미니서버 3대를 구성하고 싶다. 오픈스택 용 컨트롤러 + 컴퓨트 + 스토리지 구성으로 \u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e","tags":null,"title":"2025-05-14"},{"categories":null,"contents":"https://github.com/kubernetes/kubernetes\n쿠버네티스 딥 다이브를 시도하는 이유 시중에 쿠버네티스(이하 K8s)를 엔지니어 관점에서 활용하는 예시는 무궁무진하다. 배포, 모니터링, 유지 관리 등등 . 특히 K8s 클러스터를 배포하는 것은 kubeadm, kubespray, k3s, k0s, kind, minikube 등등 엄청나게 방법이 다양하다.\n하지만 K8s를 개발의 관점에서 접근하는 경우는 드물다. 당장 k8s 개발 환경 구축 키워드로 검색해보아도, 대부분 엔지니어 관점에서의 게시글이다.\n잘 만들어졌거나, 충분히 완성도가 높을 것이라 기대되는 K8s를 굳이 빌드해보는 이유는 무엇일까? 이에 대한 나의 선제적 답은 엔지니어와 개발자 두 가지 관점으로 있다.\n엔지니어의 관점에서, 소프트웨어 내부 구조와 동작 원리를 얼마나 깊이 이해하고 있느냐에 따라 그 도구를 사용하는 효율성은 크게 달라진다. 특히, 복잡한 시스템일수록 내부 로직을 깊이 이해하는 것은 단순한 활용 이상의 가치를 제공한다.\n이러한 이해는 단순히 현재의 요구 사항을 충족시키는 데서 그치지 않고, 예상치 못한 장애 상황이나 극한의 환경에서도 시스템의 성능과 안정성을 유지할 수 있는 확장성과 대응 능력을 제공한다. 예를 들어, 대규모 트래픽 폭증, 비정상적인 노드 장애, 또는 네트워크 단절과 같은 상황은 일반적인 환경에서는 쉽게 재현할 수 없지만, 이러한 시나리오에 대비한 설계와 배포 전략을 세우는 데에는 내부 로직에 대한 깊은 이해가 필수적이다.\n또한, K8s를 코드 수준으로 분석하면서 얻게 되는 경험은 단순히 작동 방식을 넘어, 시스템의 다양한 구성 요소가 어떻게 상호작용하는지, 이를 최적화하거나 커스터마이징하는 방법은 무엇인지에 대한 통찰력을 제공한다. 이는 특정 프로젝트의 요구 사항에 맞는 맞춤형 솔루션을 설계하거나, 시스템 병목을 제거하고 성능을 극대화하는 데 직접적인 도움을 준다.\n개발자 관점에서는 Kubernetes가 단순히 컨테이너 오케스트레이션 도구로서의 가치를 넘어 오픈소스 생태계와 Go 언어 기반 프로젝트의 대표적인 성공 사례로 꼽힌다는 점이다. 이는 단순히 소프트웨어를 빌드하고 사용하는 것을 넘어, 오픈소스 협업의 구조, 코드 품질 관리, 대규모 커뮤니티 기여 방식 등을 깊이 이해하는 데 훌륭한 케이스 스터디가 될 수 있다.\n특히, Kubernetes는 복잡하고 정교하게 설계된 코드베이스를 가지고 있어, Go 언어의 고급 활용 사례를 학습하고, 효율적이고 확장 가능한 소프트웨어 설계를 탐구하기에 적합하다. 이를 통해 단순히 Kubernetes 자체의 동작 원리를 배우는 것뿐만 아니라, 대규모 오픈소스 프로젝트의 개발 및 운영 방식을 체득할 수 있다.\n내 실력으로 쿠버네티스 생태계를 얼마나 깊은 수준으로 탐험할 수 있을까 걱정이지만, 조심스러운 여정을 시작해보려 한다.\n개발 환경 구축 구체적인 방법은 다음 주소에서 확인할 수 있다. https://github.com/kubernetes/community/blob/master/contributors/devel/README.md\nBuilding Kubernetes with Docker hack/local-up-cluster.sh 예시 : https://medium.com/@ElieXU/k8s-cluster-setup-from-source-code-9e38354a24fd 환경 셋업 아래 환경에서 프로젝트를 생성하여 진행하였다. cpu : 16 코어 mem : 60 os : rocky 9.4 go 1.23.4\n빌드 깃허브 레포지토리 readme를 확인하면 아래와 같은 두 가지 방법이 존재한다.\ngolang 기반 환경 git clone https://github.com/kubernetes/kubernetes cd kubernetes make 실제로 빌드 시에 시간 많이 소요되진 않는다. 거의 금방 완료된다. golang 기반으로 빌드 하였을 때 결과물은 다음과 같다.\n$ pwd /home/syyang/projects/kubernetes/_output/bin $ ls apiextensions-apiserver e2e.test go-runner kube-aggregator kube-controller-manager kubectl-convert kube-log-runner kube-proxy mounter e2e_node.test ginkgo kubeadm kube-apiserver kubectl kubelet kubemark kube-scheduler docker 환경 hack/local-up-cluster.sh 문서를 따라하기 위해 다음 방법을 사용한다.\ngit clone https://github.com/kubernetes/kubernetes cd kubernetes make quick-release 해당 방식은 10~15분 정도 시간이 소요 된다.\n$ make quick-release +++ [0120 14:01:32] Verifying Prerequisites.... +++ [0120 14:01:32] Building Docker image kube-build:build-9bf87f211d-5-v1.33.0-go1.23.4-bullseye.0 +++ [0120 14:05:22] Creating data container kube-build-data-9bf87f211d-5-v1.33.0-go1.23.4-bullseye.0 +++ [0120 14:05:22] Syncing sources to container +++ [0120 14:05:28] Running build command... +++ [0120 14:05:31] Building go targets for linux/amd64 k8s.io/apiextensions-apiserver (static) k8s.io/component-base/logs/kube-log-runner (static) k8s.io/kube-aggregator (static) k8s.io/kubernetes/cluster/gce/gci/mounter (static) k8s.io/kubernetes/cmd/kube-apiserver (static) k8s.io/kubernetes/cmd/kube-controller-manager (static) k8s.io/kubernetes/cmd/kube-proxy (static) k8s.io/kubernetes/cmd/kube-scheduler (static) k8s.io/kubernetes/cmd/kubeadm (static) k8s.io/kubernetes/cmd/kubelet (non-static) +++ [0120 14:06:39] Building go targets for linux/amd64 k8s.io/component-base/logs/kube-log-runner (static) k8s.io/kubernetes/cmd/kube-proxy (static) k8s.io/kubernetes/cmd/kubeadm (static) k8s.io/kubernetes/cmd/kubelet (non-static) +++ [0120 14:06:45] Building go targets for linux/amd64 k8s.io/kubernetes/cmd/kubectl (static) k8s.io/kubernetes/cmd/kubectl-convert (static) +++ [0120 14:06:51] Building go targets for linux/amd64 github.com/onsi/ginkgo/v2/ginkgo (non-static) k8s.io/kubernetes/test/conformance/image/go-runner (non-static) k8s.io/kubernetes/test/e2e/e2e.test (test) +++ [0120 14:07:13] Building go targets for linux/amd64 github.com/onsi/ginkgo/v2/ginkgo (non-static) k8s.io/kubernetes/cmd/kubemark (static) k8s.io/kubernetes/test/e2e_node/e2e_node.test (test) +++ [0120 14:07:34] Syncing out of container +++ [0120 14:07:37] Building tarball: src +++ [0120 14:07:37] Building tarball: manifests +++ [0120 14:07:37] Starting tarball: client linux-amd64 +++ [0120 14:07:37] Waiting on tarballs gtar: Removing leading `/\u0026#39; from member names gtar: Removing leading `/\u0026#39; from hard link targets gtar: Removing leading `/\u0026#39; from member names gtar: Removing leading `/\u0026#39; from member names gtar: Removing leading `/\u0026#39; from hard link targets gtar: Removing leading `/\u0026#39; from member names +++ [0120 14:07:42] Building tarball: node linux-amd64 +++ [0120 14:07:42] Building images: linux-amd64 +++ [0120 14:07:42] Starting docker build for image: kube-apiserver-amd64 +++ [0120 14:07:42] Starting docker build for image: kube-controller-manager-amd64 +++ [0120 14:07:42] Starting docker build for image: kube-scheduler-amd64 +++ [0120 14:07:42] Starting docker build for image: kube-proxy-amd64 +++ [0120 14:07:42] Starting docker build for image: kubectl-amd64 +++ [0120 14:07:46] Deleting docker image registry.k8s.io/kube-proxy-amd64:v1.33.0-alpha.0.536_8b1fe81dfa5ca3 +++ [0120 14:07:47] Deleting docker image registry.k8s.io/kubectl-amd64:v1.33.0-alpha.0.536_8b1fe81dfa5ca3 +++ [0120 14:07:47] Deleting docker image registry.k8s.io/kube-scheduler-amd64:v1.33.0-alpha.0.536_8b1fe81dfa5ca3 +++ [0120 14:07:47] Deleting docker image registry.k8s.io/kube-controller-manager-amd64:v1.33.0-alpha.0.536_8b1fe81dfa5ca3 +++ [0120 14:07:49] Deleting docker image registry.k8s.io/kube-apiserver-amd64:v1.33.0-alpha.0.536_8b1fe81dfa5ca3 +++ [0120 14:07:49] Docker builds done +++ [0120 14:07:49] Building tarball: server linux-amd64 +++ [0120 14:08:21] Building tarball: final +++ [0120 14:08:21] Waiting on test tarballs +++ [0120 14:08:21] Starting tarball: test linux-amd64 +++ [0120 14:08:30] Building tarball: test portable hack/local-up-cluster.sh 로컬환경에 클러스터를 배포하는 스크립트이다. etcd 가 설치되어 있어야 한다. 아래는 etcd가 없어서 새로 설치 후 다시 진행했다.\n$ export. CONTAINER_RUNTIME_ENDPOINT=\u0026#34;unix:///run/containerd/containerd.sock\u0026#34; $ sudo -E PATH=$PATH hack/local-up-cluster.sh make: Entering directory \u0026#39;/home/syyang/projects/kubernetes\u0026#39; +++ [0120 14:13:07] Building go targets for linux/amd64 k8s.io/kubernetes/cmd/cloud-controller-manager (non-static) k8s.io/kubernetes/cmd/kube-apiserver (static) k8s.io/kubernetes/cmd/kube-controller-manager (static) k8s.io/kubernetes/cmd/kubectl (static) k8s.io/kubernetes/cmd/kubelet (non-static) k8s.io/kubernetes/cmd/kube-proxy (static) k8s.io/kubernetes/cmd/kube-scheduler (static) make: Leaving directory \u0026#39;/home/syyang/projects/kubernetes\u0026#39; [sudo] password for syyang: etcd must be in your PATH You can use \u0026#39;hack/install-etcd.sh\u0026#39; to install a copy in third_party/. $ ./hack/install-etcd.sh Downloading https://github.com/etcd-io/etcd/releases/download/v3.5.17/etcd-v3.5.17-linux-amd64.tar.gz succeed PATH=\u0026#34;$PATH:/home/syyang/projects/kubernetes/third_party/etcd\u0026#34; $ PATH=\u0026#34;$PATH:/home/syyang/projects/kubernetes/third_party/etcd\u0026#34; /etc/containerd/config.toml 파일에서 SystemdCgroup = true 라인을 지워야 하고 ( 해당 환경에 과거 k8s 설치이력이 있었다면, 클러스터 성분 및 kubelet 등을 깔끔하게 제거 하는 것을 추천한다 ) sudo 권한을 사용하여 sudo -E PATH=$PATH hack/local-up-cluster.sh 로 실행하는 게 좋다.\n... pod/coredns-76b7578cff-2qlv5 condition met deployment.apps/coredns condition met 6 Create default storage class for storageclass.storage.k8s.io/standard created Local Kubernetes cluster is running. Press Ctrl-C to shut it down. Configurations: /tmp/local-up-cluster.sh.7bEbu8/kube-audit-policy-file /tmp/local-up-cluster.sh.7bEbu8/kube_egress_selector_configuration.yaml /tmp/local-up-cluster.sh.7bEbu8/kubelet.yaml /tmp/local-up-cluster.sh.7bEbu8/kube-proxy.yaml /tmp/local-up-cluster.sh.7bEbu8/kube-scheduler.yaml /tmp/local-up-cluster.sh.7bEbu8/kube-serviceaccount.key Logs: /tmp/etcd.log /tmp/kube-apiserver.log /tmp/kube-controller-manager.log /tmp/kube-proxy.log /tmp/kube-scheduler.log /tmp/kubelet.log To start using your cluster, you can open up another terminal/tab and run: export KUBECONFIG=/var/run/kubernetes/admin.kubeconfig cluster/kubectl.sh Alternatively, you can write to the default kubeconfig: export KUBERNETES_PROVIDER=local cluster/kubectl.sh config set-cluster local --server=https://localhost:6443 --certificate-authority=/var/run/kubernetes/server-ca.crt cluster/kubectl.sh config set-credentials myself --client-key=/var/run/kubernetes/client-admin.key --client-certificate=/var/run/kubernetes/client-admin.crt cluster/kubectl.sh config set-context local --cluster=local --user=myself cluster/kubectl.sh config use-context local cluster/kubectl.sh 코드 수정 후 매번 이런 식으로 클러스터를 배포해 볼 수 있다. 다만 이 과정 자체가 금방 수행된다는 느낌은 아니고 일부 수정 후에 항상 전체를 재배포해야 한다는 불만 요소가 있다. kind 등을 통해 컨테이너 수준으로 배포시에 파일 일부 변화만 감지하여 재배포하는 프로세스 등을 시도해봄직 하다.\n우선은 간단한 방법론을 알아보았는데, 더 편리한 배포 방식은 추후에 더 심도있게 응용해야할 때가 있을 더 고민을 해볼 필요가 있을 듯하다.\nkind K8s in Docker 라는 이름의 뜻 https://kind.sigs.k8s.io kind supports building Kubernetes release builds from source 라는 문장을 문서 어딘가에서 확인하였는데, 실제로 변경된 코드 사항을 빠르게 클러스터로 곧장 배포할 수 있다면 쿠버네티스 개발에 큰 도움이 되지 않을까 싶다.\n다만, 아직 정확한 방법을 찾지는 못 하였는데, 예상컨데 소스 빌드 후 kind 노드 이미지를 새로 빌드하여 kind 클러스터를 배포하는 방식이 있을 듯하고, 가장 좋은 것은 배포된 환경에서 일부 컴포넌트만 수정된 컴포넌트로 교체하는 방식이 존재하는 것이다.\n공식 페이지 resource 카테고리 확인시, CI로 사용하는 예제에 대한 영상이 많다.\n코드 훑어보기 가장 먼저 K8s를 코드 수준으로 분석하기 위해 git 코드베이스를 펼쳐보았을 때 겪은 문제가 있었다. 코드를 어디서부터 확인해야 하는지 모르겠다는 점이다. K8s 레포의 구조는 다음과 같다.\n$ ls api CHANGELOG cluster code-of-conduct.md docs go.sum go.work.sum LICENSE logo _output OWNERS_ALIASES plugin SECURITY_CONTACTS SUPPORT.md third_party build CHANGELOG.md cmd CONTRIBUTING.md go.mod go.work hack LICENSES Makefile OWNERS pkg README.md staging test vendor golang의 표준 레포 레이아웃은 해당 주소를 확인해보면 좋다. 공식적인 표준은 아니라는 점을 주의해야 한다.\n위 게시글을 참고로 보았을 때, 코드를 확인할 때 가장 먼저 확인하면 좋은 영역은 역시 cmd 하위이다.\ncmd $ ls clicheck dependencyverifier genkubedocs genutils import-boss kube-apiserver kubectl-convert kube-proxy preferredimports cloud-controller-manager fieldnamedocscheck genman genyaml importverifier kube-controller-manager kubelet kube-scheduler prune-junit-xml dependencycheck gendocs genswaggertypedocs gotemplate kubeadm kubectl kubemark OWNERS yamlfmt 익숙한 컴포넌트와 익숙하지 않은 컴포넌트들이 동시에 눈에 띈다. 예를 들면, kube 로 시작하는 컴포넌트들은 익숙하다. kubeadm, kube-apiserver, kube-controller-manager, kubectl, kubelet, kube-proxy, kube-scheduler 등등이다.\n쿠버네티스를 구성하는 핵심 컴포넌트들 모두가 하나의 레포에 모여 있다. 이를 모노레포 전략이라고 부른다. OpenStack은 기본적으로 여러 서비스에 대한 관리를 멀티 레포지토리로 처리한다. 예를 들면, Nova 코드의 원리를 확인하고 싶으면 Nova 레포지토리를 확인하면 된다.\n눈에 익숙치 않은 컴포넌트 들도 존재한다. 이름으로 짐작컨데, 문서 작성이나 의존성 체크 등 프로젝트 관리에 도움이 되는 요소라고 추측한다.\n이 수 많은 컴포넌트 중에, 쿠버네티스 구조에서 가장 중요하다고 생각이 되는 kube-apiserver 안을 살펴보자. 생각보다 아기자기한 구성이다. apiserver.go 와 app 폴더가 메인이고 특징적으로 .import-restrictions 파일이 존재한다.\nls -al . .. apiserver.go app .import-restrictions OWNERS apiserver.go 파일은 main 패키지의 역할이다. 일반적인 오픈소스들의 코드 시작부는 정말 간단한 것 같다. 추후 프로젝트를 시작할 때 고려해 볼만한 사항이다.\n/* Copyright 2014 The Kubernetes Authors. Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */ // APIServer is the main API server and master for the cluster. // It is responsible for serving the cluster management API. package main import ( \u0026#34;os\u0026#34; _ \u0026#34;time/tzdata\u0026#34; // for timeZone support in CronJob \u0026#34;k8s.io/component-base/cli\u0026#34; _ \u0026#34;k8s.io/component-base/logs/json/register\u0026#34; // for JSON log format registration _ \u0026#34;k8s.io/component-base/metrics/prometheus/clientgo\u0026#34; // load all the prometheus client-go plugins _ \u0026#34;k8s.io/component-base/metrics/prometheus/version\u0026#34; // for version metric registration \u0026#34;k8s.io/kubernetes/cmd/kube-apiserver/app\u0026#34; ) func main() { command := app.NewAPIServerCommand() code := cli.Run(command) os.Exit(code) } 핵심 로직은 \u0026quot;k8s.io/kubernetes/cmd/kube-apiserver/app\u0026quot; 쪽에 담겨 있음을 짐작할 수 있고, 프로그램의 시작이 cobra 기반의 cli tool로 되어 있다는 사실이 매력적이다. cobra 기반임을 알 수 있는 건 \u0026quot;k8s.io/component-base/cli\u0026quot; 쪽을 미리 확인했기 때문이다. 이를 별도의 component-base 경로의 cli 패키지로 정의했다는 것은 여러 프로젝트에서 공통적으로 사용하는 디자인이라고 생각할 수 있다.\npackage cli import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;github.com/spf13/cobra\u0026#34; cliflag \u0026#34;k8s.io/component-base/cli/flag\u0026#34; \u0026#34;k8s.io/component-base/logs\u0026#34; \u0026#34;k8s.io/klog/v2\u0026#34; ) staging 자연스럽게 staging 폴더로 넘어가보자. \u0026quot;k8s.io/component-base/cli\u0026quot; 파일 경로는 staging/src 폴더 하위에 있었다. staging 폴더는 Kubernetes 코드베이스의 모듈화 및 재사용성을 위한 중요한 구조적 요소이다.\nstaging 폴더에 있는 코드는 Kubernetes 코드베이스 내에서 개발 및 테스트되지만, 최종적으로는 외부 리포지토리(예: https://github.com/kubernetes/client-go)로 퍼블리싱 봇에 의해 복사된다.\nKubernetes 프로젝트는 staging 디렉토리에 정의된 모듈을 내부적으로 사용하며, Go 모듈의 replace 지시문을 활용하여 경로를 지정한다. 이를 통해 Kubernetes 프로젝트는 자체 코드를 의존성으로 처리하고, 외부에 독립적인 라이브러리로 제공할 수 있다.\nstaging 구조는 Kubernetes의 모노레포를 점진적으로 분리하여, 독립적인 마이크로 리포지토리로 전환하는 전략의 일부다. 이는 코드 재사용성과 커뮤니티 기여를 촉진하고, 특정 라이브러리의 업데이트가 Kubernetes 전체 코드베이스에 영향을 미치지 않도록 설계되었다.\n관련한 전체적인 개발 프로세스는 다음과 같다.\n개발자가 Kubernetes 메인 리포지토리에 코드 변경(PR 생성). staging 코드 변경 사항 감지: Publishing Bot이 변경을 감지하고, 동기화 규칙에 따라 작업 실행. 외부 리포지토리로 코드 복사: rules.yaml에 지정된 대로 외부 리포지토리에 PR 생성. 의존성 업데이트: 관련 리포지토리 간 의존성을 업데이트하고, 테스트를 통해 검증. 꽤나 멋진 구조라고 생각한다.\npkg cmd/kube-apiserver/.import-restrictions 를 체크해보면, k8s.io/kubernetes/pkg 항목이 존재하는 것을 볼 수 있다.\nrules: - selectorRegexp: k8s[.]io/kubernetes allowedPrefixes: - k8s.io/kubernetes/cmd/kube-apiserver - k8s.io/kubernetes/pkg - k8s.io/kubernetes/plugin - k8s.io/kubernetes/test/utils - k8s.io/kubernetes/third_party pkg 폴더는 golang에서 흔히 사용되는 레포지토리 레이아웃 관점에서 내부 구현 세부사항과 공통 유틸리티를 담는 공간이지만, 근본적으로 외부 사용자가 사용할 수 있는 코드 세트이다. 즉, 이 폴더는 프로젝트 내부와 외부 모두에서 재사용 가능한 코드를 패키지 형태로 제공한다.\n실제 사용 예시로 cmd/kube-apiserver/app/server.go 파일의 임포트 항목을 살펴보면 다음과 같다. 거의 대부분의 임포트 항목의 경로에 pkg 폴더가 함유 됨을 알 수 있다.\npackage app import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net/url\u0026#34; \u0026#34;os\u0026#34; \u0026#34;github.com/spf13/cobra\u0026#34; apiextensionsv1 \u0026#34;k8s.io/apiextensions-apiserver/pkg/apis/apiextensions/v1\u0026#34; utilerrors \u0026#34;k8s.io/apimachinery/pkg/util/errors\u0026#34; utilruntime \u0026#34;k8s.io/apimachinery/pkg/util/runtime\u0026#34; \u0026#34;k8s.io/apiserver/pkg/admission\u0026#34; genericapifilters \u0026#34;k8s.io/apiserver/pkg/endpoints/filters\u0026#34; genericapiserver \u0026#34;k8s.io/apiserver/pkg/server\u0026#34; \u0026#34;k8s.io/apiserver/pkg/server/egressselector\u0026#34; serverstorage \u0026#34;k8s.io/apiserver/pkg/server/storage\u0026#34; utilfeature \u0026#34;k8s.io/apiserver/pkg/util/feature\u0026#34; \u0026#34;k8s.io/apiserver/pkg/util/notfoundhandler\u0026#34; \u0026#34;k8s.io/apiserver/pkg/util/webhook\u0026#34; clientgoinformers \u0026#34;k8s.io/client-go/informers\u0026#34; \u0026#34;k8s.io/client-go/rest\u0026#34; cliflag \u0026#34;k8s.io/component-base/cli/flag\u0026#34; \u0026#34;k8s.io/component-base/cli/globalflag\u0026#34; \u0026#34;k8s.io/component-base/featuregate\u0026#34; \u0026#34;k8s.io/component-base/logs\u0026#34; logsapi \u0026#34;k8s.io/component-base/logs/api/v1\u0026#34; _ \u0026#34;k8s.io/component-base/metrics/prometheus/workqueue\u0026#34; \u0026#34;k8s.io/component-base/term\u0026#34; utilversion \u0026#34;k8s.io/component-base/version\u0026#34; \u0026#34;k8s.io/component-base/version/verflag\u0026#34; \u0026#34;k8s.io/klog/v2\u0026#34; aggregatorapiserver \u0026#34;k8s.io/kube-aggregator/pkg/apiserver\u0026#34; \u0026#34;k8s.io/kubernetes/cmd/kube-apiserver/app/options\u0026#34; \u0026#34;k8s.io/kubernetes/pkg/capabilities\u0026#34; \u0026#34;k8s.io/kubernetes/pkg/controlplane\u0026#34; controlplaneapiserver \u0026#34;k8s.io/kubernetes/pkg/controlplane/apiserver\u0026#34; \u0026#34;k8s.io/kubernetes/pkg/controlplane/reconcilers\u0026#34; kubeapiserveradmission \u0026#34;k8s.io/kubernetes/pkg/kubeapiserver/admission\u0026#34; ) golang을 다루다보면 패키지의 순환 의존성을 조심할 필요가 있다. 특정 패키지에서 호출(import)되는 패키지는, 자신을 호출하는 패키지를 호출 하면 안된다. 특히 모노레포 생태계인 K8s 생태계에서는 조심해야한 성질이며, 이러한 부분을 아마도 현명하게 컨트롤하고 있을 것이라 생각한다. .import-restrictions 가 그 노력 중 하나이다. 빌드 프로세스에서 위반 여부를 자동으로 검증 한다고 한다.\n또한, 패키지 간 호출의 변화는 코드 리뷰 프로세스를 통해 검증 된다. OWNERS 파일 에서는 패키지 간의 관리자를 정하고 있는데, 특정 디렉터리와 관련된 코드 변경은 해당 디렉터리의 전문가(Reviewer 또는 Approver)에 의해 검토되게 되는 시스템이다. 대표적으로 pkg/api/OWNERS 를 살펴보면 다음과 같다.\n# See the OWNERS docs at https://go.k8s.io/owners # Disable inheritance as this is an api owners file options: no_parent_owners: true filters: \u0026#34;.*\u0026#34;: approvers: - api-approvers reviewers: - api-reviewers # examples: # pkg/api/types.go # pkg/api/*/register.go \u0026#34;([^/]+/)?(register|types)\\\\.go$\u0026#34;: labels: - kind/api-change 패키지 구조는 가급적이면 2~3단계 이상의 폴더보다 더 깊게 생성되지 않는다. 또한 테스트 파일도 많이 작성해 둔다. kubernetes/pkg/api 경로를 예를 들면 이러하다.\n$ tree . . ├── endpoints │ └── testing │ └── make.go ├── job │ ├── warnings.go │ └── warnings_test.go ├── legacyscheme │ └── scheme.go ├── node │ ├── util.go │ └── util_test.go ├── OWNERS ├── persistentvolume │ ├── util.go │ └── util_test.go ├── persistentvolumeclaim │ ├── OWNERS │ ├── util.go │ └── util_test.go ├── pod │ ├── OWNERS │ ├── testing │ │ └── make.go │ ├── util.go │ ├── util_test.go │ ├── warnings.go │ └── warnings_test.go ├── service │ ├── OWNERS │ ├── testing │ │ └── make.go │ ├── util.go │ ├── util_test.go │ ├── warnings.go │ └── warnings_test.go ├── servicecidr │ ├── servicecidr.go │ └── servicecidr_test.go ├── storage │ ├── util.go │ └── util_test.go ├── testing │ ├── applyconfiguration_test.go │ ├── backward_compatibility_test.go │ ├── compat │ │ └── compatibility_tester.go │ ├── conversion.go │ ├── conversion_test.go │ ├── copy_test.go │ ├── deep_copy_test.go │ ├── defaulting_test.go │ ├── doc.go │ ├── fuzzer.go │ ├── install.go │ ├── meta_test.go │ ├── node_example.json │ ├── OWNERS │ ├── replication_controller_example.json │ ├── serialization_proto_test.go │ ├── serialization_test.go │ └── unstructured_test.go └── v1 ├── endpoints │ ├── util.go │ └── util_test.go ├── OWNERS ├── persistentvolume │ ├── util.go │ └── util_test.go ├── pod │ ├── util.go │ └── util_test.go ├── resource │ ├── helpers.go │ └── helpers_test.go └── service ├── util.go └── util_test.go 이외 위에서 살펴본 폴더 이외에도 test, hack, build, api, plugin 등등의 여러 폴더가 존재한다. 재미 삼아 api/openapi-spec/swagger.json 파일을 열어보면, 8만 줄에 가까운 엄청난 길의 파일도 만나볼 수 있다. ( 아마도 자동으로 생성될 것이라 예상한다 )\nK8s는 탄생 10주년을 맞이하는 정말 방대한 프로젝트이다. 한 번에 모든 컴포넌트를 분석할 순 없다. 처음부터 코드를 분석하는 것은 아주 어려운 일이다. 거의 대부분의 경우 필요에 의해 코드를 찾아가는 것이 일반적이다. 그러다 우연히 처음 보는 영역에 발을 들이는 순간에 각 폴더 별로 존재하는 README.md 파일을 첫 지침서로서 활용하는 편이 좋겠다.\n정리 Kubernetes는 컨테이너 오케스트레이션을 넘어 분산 시스템의 다양한 요구를 충족시키는 플랫폼이다. 이번 글에서는 Kubernetes 코드베이스의 주요 구조를 살펴보았으며, cmd, staging, pkg 디렉터리의 역할과 목적을 분석했다. 이를 통해 Kubernetes 내부 구조를 이해하고, 필요에 따라 기능을 커스터마이징하거나 디버깅하는 데 활용할 수 있다.\nKubernetes를 제대로 이해하려면 코드 구조를 아는 것에서 그치지 않고, 클러스터가 실제로 동작하는 원리를 탐구해야 한다. 특히, “파드 생성 과정”은 Kubernetes의 핵심 기능 중 하나로, 클러스터의 주요 컴포넌트가 어떻게 상호작용하며 워크로드를 배포하는지를 보여주는 중요한 흐름이다.\n다음 글에서는 Kubernetes의 파드 생성 과정을 다루며, 클러스터 내부에서 일어나는 동작 원리를 구체적으로 파악 해보고자 한다.\n","date":"January 2, 2025","hero":"/images/hero/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EA%B0%80%20%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C.png","permalink":"https://kubesy.com/posts/300.-study/301.-kubernetes-deep-dive/hello-k8s-dev-world/","summary":"\u003cp\u003e\u003ca href=\"https://github.com/kubernetes/kubernetes\" target=\"_blank\" rel=\"noopener\"\u003ehttps://github.com/kubernetes/kubernetes\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"쿠버네티스-딥-다이브를-시도하는-이유\"\u003e쿠버네티스 딥 다이브를 시도하는 이유\u003c/h3\u003e\n\u003cp\u003e시중에 쿠버네티스(이하 K8s)를 엔지니어 관점에서 활용하는 예시는 무궁무진하다. 배포, 모니터링, 유지 관리 등등 .\n특히 K8s 클러스터를 배포하는 것은 kubeadm, kubespray, k3s, k0s, kind, minikube 등등 엄청나게 방법이 다양하다.\u003c/p\u003e\n\u003cp\u003e하지만 K8s를 개발의 관점에서 접근하는 경우는 드물다. 당장 \u003ccode\u003ek8s 개발 환경 구축\u003c/code\u003e 키워드로 검색해보아도, 대부분 엔지니어 관점에서의 게시글이다.\u003c/p\u003e\n\u003cp\u003e잘 만들어졌거나, 충분히 완성도가 높을 것이라 기대되는 K8s를 굳이 빌드해보는 이유는 무엇일까? 이에 대한 나의 선제적 답은 엔지니어와 개발자 두 가지 관점으로 있다.\u003c/p\u003e","tags":null,"title":"1. Hello, k8s Dev World!"},{"categories":null,"contents":"들어가기 앞서 \u0026hellip; 저는 비전공자 출신이고, 이제 곧 만 3년의 경력을 채우는 클라우드 도메인 쪽 개발자 입니다. ( 사실 개발자와 DevOps 엔지니어 그 어딘가에 걸쳐 있다고 생각하긴 하는데 \u0026hellip; )\n현재 제 주력 언어는, go와 python 인데요. 예전부터 java spring을 그래도 한 번은 경험 해봐야겠다는 생각을 가지고 있었습니다. (한국에서 백엔드는 자바 밖에 안 뽑아요 \u0026hellip;)\n그러다보니 스프링 부트 핵심 가이드 라는 책을 이전에 사놓고 방치해두고 있었다가, 연말 휴가를 맞이하여 한 번 도전해봐야겠다는 생각이 들었습니다.\n책을 내용을 기반으로 정리하되, 저만의 색깔을 덧입혀서 글을 써보려고 합니다. 아무쪼록 저와 비슷한 상태에 있는 독자 분들에게 도움이 되길 바랍니다.\n개념 자바 스프링 부트는 자바 스프링을 좀 더 쉽게 다룰 수 있게 합니다. 자바 스프링 만으로 프로젝트를 구축하려면, 아주 복잡한 설정들을 수행해야 하는데, 스프링 부트를 사용하면 이를 보다 약소화 할 수 있습니다.\nSpring 이라는 이름의 의미는, 개발자들에게 봄이 왔다는 뜻이라나 \u0026hellip;\n스프링의 가장 큰 특징은 의존성 주입 입니다. 스프링의 의존성 주입은 객체 간 결합도를 줄이고, 유연성과 테스트 가능성을 높이는 핵심 개념입니다. 이를 통해 스프링 애플리케이션은 더 관리하기 쉽고 확장 가능한 구조를 가지게 됩니다. 스프링의 DI는 현대적인 애플리케이션 설계에서 매우 중요한 역할을 합니다.\nDI는 \u0026ldquo;제어의 역전\u0026rdquo;(Inversion of Control, IoC) 원칙을 기반으로 합니다. 객체의 생성을 개발자가 직접 제어하지 않고, 스프링 컨테이너가 관리하도록 함으로써 코드의 유연성과 확장성을 보장합니다.\n결합도 감소\n객체 간의 의존 관계를 코드에서 직접 명시하지 않아 유연성이 높아집니다. 한 객체의 변경이 다른 객체에 미치는 영향을 최소화합니다. 테스트 용이성\nDI를 통해 의존성을 주입받으므로, 테스트 시에는 **모의 객체(Mock)**를 쉽게 주입할 수 있습니다. 유닛 테스트와 통합 테스트를 보다 쉽게 수행할 수 있습니다. 재사용성 증가\n객체가 특정 구현체에 의존하지 않으므로, 인터페이스나 추상 클래스만 정의하면 다양한 구현체를 주입받아 사용할 수 있습니다. 객체 생명주기 관리\n스프링 컨테이너가 객체의 생성, 초기화, 소멸까지 관리하므로 코드가 간결해지고 유지보수가 쉬워집니다. IoC 컨테이너는 애플리케이션의 객체(빈)를 생성하고, 의존 관계를 설정한 뒤 애플리케이션이 실행될 때 이를 제공합니다.\n처리 과정:\n빈(Bean) 정의 @Component, @Service, @Repository 등 애노테이션을 사용해 스프링이 관리할 빈을 정의합니다. 의존 관계 설정 @Autowired 또는 생성자를 통해 의존성을 정의합니다. 빈 생성 스프링 컨테이너가 애플리케이션 시작 시점에 빈을 생성하고 의존성을 주입합니다. DI 의 구현 방식은 크게 세 가지로 나뉩니다. 다만 대부분의 경우, 생성자 주입이 권장 됩니다.\n생성자 주입 @Component public class Service { private Repository repository; @Autowired public void setRepository(Repository repository) { this.repository = repository; } } Setter 주입 @Component public class Service { @Autowired private Repository repository; } 필드 주입 @Component public class Service { @Autowired private Repository repository; } DI 이외에도 AOP(Aspect-Oriented Programming 와 같은 특징이 있다고 합니다.\n사실 여기까지만 읽었을 때, 구체적인 구현을 보기 전까지는 조금 모호하다라는 생각이 듭니다. 또 Go를 제 첫 언어로 삼아서 그런지 자꾸 비교를 해가면서 이해하게 되는 양상이 있습니다. 예를 들어 MVC 와 같은 개념은 golang에서도 은연 중 사용하고 있었을 지 모르지만, 그다지 본격적으로 개념부터 알고 들어가진 않았어었습니다.\n아래의 그림을 보면, 데이터베이스 강의 앞 부분에서 보았던 개념과 매칭됩니다.\nGo 에서의 웹개발(gin-gonic)과, Java Spring Boot 를 통한 웹개발을 비교해가며 학습할 때, 개념적 접근의 차이가 느껴집니다. 예를들어 Java Spring Boot 에서 논하는 MVC 등이 Go를 사용할 때는 엄밀하게 따져가면서 개발하지 않았기 때문입니다. 사실 어느 정도는 비슷한 컨셉을 공유하고 있을 것 같은데, 이러한 차이는 어디서 오는 걸까요? Java (Spring Boot):\nJava는 객체지향 언어로 설계되어 있으며, 복잡한 비즈니스 로직을 계층화된 방식으로 구성하는 데 강점을 가집니다. Spring Boot는 엔터프라이즈 환경에서 확립된 MVC(Model-View-Controller) 패턴을 기반으로 한 구조를 강조하며, 컨벤션을 통해 개발을 간소화하려는 목적을 갖고 있습니다. 프레임워크 자체에서 DI(Dependency Injection), AOP(Aspect-Oriented Programming), 그리고 풍부한 어노테이션 지원 등을 제공해 복잡한 구조를 깔끔하게 관리하도록 돕습니다. Go (gin-gonic):\nGo는 최소주의(minimalism)를 기반으로 설계된 언어입니다. 코드가 단순하고 읽기 쉬우며, 복잡한 추상화보다는 실용적인 접근을 강조합니다. gin-gonic은 Go 언어의 철학을 따르는 경량 웹 프레임워크로, 불필요한 구조를 강요하지 않고, 개발자가 직접 필요한 패턴(MVC 포함)을 구성하도록 허용합니다. Go에서는 보통 \u0026ldquo;프로젝트 구조를 단순하게 유지\u0026quot;하는 것이 기본 철학에 가깝기 때문에, 엄격한 MVC 구조가 필요 없을 수도 있습니다. 위는 디자인 패턴 종류를 분류 해놓은 것 입니다. 스프링은 이중에 싱글톤 패턴, 팩토리 메서드, 프록시, 템플릿 메서드, 어댑터 등등의 다양한 원칙을 내재화 있다고 합니다.\n환경 구축 반골기질 때문에, 모두가 인텔리제이를 주장할 때 본인은 vscode를 고집하고 싶습니다. 그리고 패키지들을 무조건 최신에 가깝게 설정하고 싶어요 참고자료 https://it-ability.tistory.com/92 https://huimang2.github.io/etc/ubuntu-dev-env vscode 확장 프로그램 다운로드 Spring Boot Extension Pack Java Extension Pack JDK 설치 $ sudo dnf install java-17-openjdk java-17-openjdk-devel $ java --version openjdk 17.0.13 2024-10-15 LTS OpenJDK Runtime Environment (Red_Hat-17.0.13.0.11-1) (build 17.0.13+11-LTS) OpenJDK 64-Bit Server VM (Red_Hat-17.0.13.0.11-1) (build 17.0.13+11-LTS, mixed mode, sharing) $ readlink -f /usr/bin/java /usr/lib/jvm/java-17-openjdk-17.0.13.0.11-4.el9.x86_64/bin/java $ vi ~/.bashrc ... export JAVA_HOME=/usr/lib/jvm/java-17-openjdk export PATH=$PATH:$JAVA_HOME/bin ... $ source ~/.bashrc https://start.spring.io 에서 프로젝트 설정\nGenerate 후 폴더 압축 해제. -\u0026gt; vscode 에서 java projects 라는 ui에서 생성해도 됩니다. 참고로 위의 Package 네임으로 설정하면 문법 오류인가 봅니다.\nvscode settings.json 에 아래 와 같이 설정해줘서 자바 home 경로를 알 수 있게 해주어야 합니다.\n{ \u0026#34;java.jdt.ls.java.home\u0026#34;: \u0026#34;/usr/lib/jvm/java-17-openjdk\u0026#34; } 자 이제 생성된 코드 환경에서 몇 가지 구성을 확인해봅시다.\n첫 번째로 gradle 관련 항목입니다. 그 다음은 Spring Boot Dashboard 입니다. 현재 환경은 다른 프로세스에서 8080 포트를 사용하고 있습니다. 기본 시작 포트를 18080으로 바꿔봅니다.\nsrc/main/resources/application.properties 파일을 수정합니다.\nspring.application.name=demo server.port=18080 구동! src/main/java/com/example/demo/controller/DemoController.java 파일을 만들어서 아래처럼 코드를 추가 해줍니다.\npackage com.example.demo.controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class DemoController { @RequestMapping(\u0026#34;/demo\u0026#34;) public String hello() { return \u0026#34;Hello, World!\u0026#34;; } } 몇 가지 포인트를 찾아보면, 두 가지의 어노테이션을 임포트하였고, /demo라는 경로로 들어가는 경우 Hello, World! 를 리턴해주는 정말 간단한 로직입니다.\n솔직하게, import org.springframework.web.bind.annotation.RequestMapping; 등을 써야한다는 사실 자체 처음 알았고, 그 내부 로직이 무엇인지는 모릅니다. 그저 예제를 따라했을 뿐인데요.\n이러한 요소들을 파악하고, 좀 더 깊게 들어가면 기능의 구체적 구현 방식까지도 확인하는 그런 과정이 스프링을 이해하는 과정이 아닐까 싶은 생각이 들었습니다.\n","date":"December 24, 2024","hero":"/images/hero/spring%20boot.png","permalink":"https://kubesy.com/posts/300.-study/303.-java-spring-boot-/1.-%EA%B0%9C%EB%85%90-%EB%B0%8F-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EA%B0%84%EB%8B%A8%ED%95%9C-%EA%B5%AC%EB%8F%99/","summary":"\u003ch3 id=\"들어가기-앞서-\"\u003e들어가기 앞서 \u0026hellip;\u003c/font\u003e\u003c/h3\u003e\n\u003cp\u003e저는 비전공자 출신이고, 이제 곧 만 3년의 경력을 채우는 클라우드 도메인 쪽 개발자 입니다. ( 사실 개발자와 DevOps 엔지니어 그 어딘가에 걸쳐 있다고 생각하긴 하는데 \u0026hellip; )\u003c/p\u003e\n\u003cp\u003e현재 제 주력 언어는, go와 python 인데요. 예전부터 java spring을 그래도 한 번은 경험 해봐야겠다는 생각을 가지고 있었습니다. (한국에서 백엔드는 자바 밖에 안 뽑아요 \u0026hellip;)\u003c/p\u003e\n\u003cp\u003e그러다보니 \u003ccode\u003e스프링 부트 핵심 가이드\u003c/code\u003e 라는 책을 이전에 사놓고 방치해두고 있었다가, 연말 휴가를 맞이하여 한 번 도전해봐야겠다는 생각이 들었습니다.\u003c/p\u003e","tags":null,"title":"1. 개념 및 환경 구축 그리고 간단한 구동"},{"categories":null,"contents":"","date":"September 12, 2022","hero":"/images/hero/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EA%B0%80%20%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C.png","permalink":"https://kubesy.com/posts/500.-tech_dev/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4-%EA%B8%B0%EB%B3%B8/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EA%B0%80-%EB%AD%90%EC%A7%802/","summary":"","tags":null,"title":"쿠버네티스가 뭐지 2"},{"categories":null,"contents":"22년도에 작성했던, 일반인을 위한 쿠버네티스 소개글입니다\u0026hellip; 배운지 몇달 안 된 상태에서 썼던 글이라 각종 (이상한) 추상적인 표현이 많습니다.\n안녕하세요. 좋은 기회를 통해 최근 공부하고 있는 IT 기술인 쿠버네티스에 대해 소개 해드리고자 합니다.\n쿠버네티스? 최근 NHN사의 클라우드 교육을 다녀왔었습니다. 클라우드는 이제 많은 사람이 쉽고 편하게 사용하는 기술이지요? 매킨토시를 쓰거나, 윈도우를 쓸 때 icloud, OneDrive등의 기능을 쓰시는 분이 많을테고, 구글에서도 구글 드라이브에 자료를 저장하는 등의 경험이 있으실 것 같습니다. 그런 클라우드 시장에서 주목하는 기술 중 하나가 쿠버네티스 입니다.\n쿠버네티스에 대해 처음 들으시는 분들이 계실 것 같습니다. 저도 몇 달 전만 하더라도 일전에 한 번도 들어본 적 없는 이름이었습니다. 그래서 일까요? 왠지 신기술 처럼 느껴졌었네요. 하지만 쿠버네티스가 유명해 진 것이 최근이라고 하더라도 따끈따끈한 존재라기엔 나이가 꽤나 있습니다. 무려 8년 전인 2014년에 등장한 존재이지요. 구글과 리눅스 재단이 설립한 CNCF(Cloud Native Computing Foundation)에서 공식으로 쿠버네티스를 오픈소스화 하였습니다. 지금까지 지속적으로 업데이트 되고 있구요. 이미 기술적으로 성숙화 단계에 있다고들 하네요.\n쿠버네티스는 \u0026lsquo;가상화\u0026rsquo;나 \u0026lsquo;컨테이너\u0026rsquo; 혹은 \u0026lsquo;도커\u0026rsquo;와 \u0026lsquo;MSA(마이크로서비스 아키텍쳐)\u0026rsquo; 등의 키워드와 아주 밀접한 관계에 있습니다. 그렇기에 클라우드 환경과 아주 어울리는 기술이 되고 많은 이들의 주요한 관심을 끌고 있지요. 현재 클라우드 환경과 마이크로서비스 아키텍쳐가 가지는 장점과 매력은 세간에서 각광받는 키워드 일 것 같습니다. 아마 여러분 중에서도 마이크로서비스 아키텍쳐에 대해 이미 들어보신 분도 있을테고 실제로 활용해보신 분도 계실 것 같습니다. MSA를 채택한 가장 유명한 회사로 넷플릭스가 있습니다.\n혹시, 위에 언급된 여러 키워드 중에, 얼핏 들어보았는데 생소하거나 아니면 무슨 이야기를 하려는 지 전혀 감이 오지 않으시는 분 있으실까요? 정말 다행이네요. 이 글은 쿠버네티스를 처음 들어보시는 분들을 위해 약간의 도움을 드리고자 작성되었습니다. 한 번쯤 스쳐 지나가면서 보면 좋겠다 싶은 느낌으로요! (솔직히 쿠버네티스를 접한지 얼마되지 않았기 때문에 아주 깊은 수준의 기술을 설명해드릴 자신이 없네요 😅 )\n쿠버네티스에 대해 처음 들어보시는 분들께 제가 알고 있는 한에서 최대한 쉽게, 무엇을 위한 기술인지 설명 드리고자 합니다. 또한 어떤 이유로 쿠버네티스를 공부하고 있는지, 이것으로 뭘하고 있는지, 뭘 하려고 하는지 설명드릴 수 있는 기회가 되었으면 좋겠습니다.\n천천히 개념 접근하기 우선 쿠버네티스라는 말 자체와 친해져볼까요? Kubernetes란 명칭은 키잡이(helmsman)나 파일럿을 뜻하는 그리스어입니다. IT 기술 용어치고는 꽤나 특이한 의미를 가지고 있네요. 일종의 상징이나 비유 같은 걸까요? 실제로 쿠버네티스 로고 이미지는 배에서 사용할 법한 키로 되어있습니다. 심지어 바다를 떠올리게 하는 푸른색으로 뒤덮혀있지요.\n우리는 배 위에서 키를 잡는 사람을 선장이라 부릅니다. 선장은 바다 위를 누비며 자신을 따르는 선원들을 지휘하고 관리합니다. 영화 캐리비안의 해적에서 잭 스패로우가 그랬듯이요. 선장은 간단한 표현으로 배 위의 모든 것을 운영을 하는 사람입니다. 쿠버네티스의 로고가 \u0026lsquo;키\u0026rsquo;로 만들어진 이유가 바로 이것입니다. 모든 리더가 그러하듯, 키잡이(쿠버네티스)의 핵심적인 요소가 바로 \u0026lsquo;운영\u0026rsquo; 혹은 \u0026lsquo;관리\u0026rsquo;거 든요.\n구체적으로 무엇을 운영 혹은 관리 하는 것 일까요? 먼저 잭 스페로우가 뭘 했는지 부터 되새겨 봅시다.\n캐리비안의 해적 1편의 메인 소재였던 수많은 금화가 담긴 거대한 (저주 받은) 보물 상자를 기억하시나요? 잭 스패로우를 포함한 당대 해적, 그 중 선장들은 선원들을 부리며 단 하나의 목표에 사로 잡혀 있었습니다. 바로 보물을 찾아 영원한 명성과 부귀영화를 누리는 것 입니다. 보물 상자가 배 위에 올라온 순간 키잡이에게는 하나의 임무가 생깁니다. 육지까지 안전하게 보물을 운송하는 것입니다.\n위험의 요소는 참으로 많습니다. 다른 해적들에게서 지켜내는 게 최우선이구요. 또한 내부적으로 보물 상자를 훔쳐 달아나려는 선원도 관리해야 하고요. 또는 이외에 기이한 날씨 같이 기상천외한 현상으로부터 항해를 방해는 요소도 있었지요. 영화를 보면서 느낀 점이지만, 저런 환경에서는 참 살기 힘들었을 것 같아요.\n평화의 시대인 오늘날의 키잡이들은 상황이 좀 더 낫습니다. 과거보다 위험의 요소가 더 적다고 할까요? 단적으로 아래 사진처럼 모두가 탐내던 배 위의 귀중한 \u0026lsquo;보물 상자\u0026rsquo;는 수많은 \u0026lsquo;컨테이너 상자\u0026rsquo;로 대체 되었습니다. 여전히 바다 위로 선박을 노리는 해적들이 간간히 나타난다지만, 아주 극소수의 해프닝이 되었네요 (허나 무서운 일이지요). 저는 이분들 덕분에 아마존에서 주문한 해외 스타워즈 굿즈가 컨테이너 속에 담겨 안전하게 배송되어 너무나 행복합니다.\nIT기술을 설명한다면서 웬 뚱딴지 같은 이야기인가 싶으시겠지요? 너그러운 마음으로 이해를 돕기위한 긴 준비 단계였다고 생각해주세요. 사실은요, IT기술 쿠버네티스도 위의 예시들과 별반 다르지 않습니다.\n쿠버네티스는 컨테이너를 관리 운영하는 데 사용합니다. 그래서 컨테이너 오케스트레이션(Container Orchestration) 도구라고도 불리지요. 컴퓨터 세상에도 여러가지 위험요소 같은 것들이 많잖아요? 예를 들어 프로그램 켜놓고 까먹는다 던가, 필요한 파일을 필요할 때 못 찾는다던가 하는 느낌으로요. 컨테이너를 관리하는 데도 비슷한 일이 있는데요 …\n잠깐, 제가 아는 그 컨테이너가 맞아요? 아, 컨테이너가 뭔지부터 설명을 드려야 겠네요.\n위의 사진 같이 실생활 용품 가득 넣어진 화물 컨테이너를 생각하신다면, 아닙니다. 만약 그런거라면 쿠버네티스는 해운사에서 사용하는 프로그램쯤 되려나요? 😁\nIT 세계에서 언급되는 컨테이너는 하나의 \u0026lsquo;운영 체제 커널\u0026rsquo;에서 다른 프로세스에 영향을 받지 않고 \u0026lsquo;독립적으로 실행되는 프로세스\u0026rsquo; 상태를 의미 합니다. 제 표현이긴 하지만 컴퓨터 세상의 화물 컨테이너라고 해도 무관해보여요. 실제로 컨셉을 저기서 많이 따온 것 이구요.\n어떤 컨셉인지 화물 컨테이너와의 연관점으로 쉽게 이해해 봅시다. 우리가 사진으로 보듯 화물 컨테이너 외부는 다들 색깔만 다르지 비슷한 모양과 크기로 쌓여져 있습니다. 여러 화물 컨테이너가 같은 선박 위에 놓여있는 상황은 여러 인스턴스들이 \u0026lsquo;하나의 운영 체제 커널 위\u0026rsquo;에 있는 것과 비슷합니다.\n또, 중요한 것은 내부입니다. 화물 컨테이너 겉만 봐서는 내부에 어떤 물건이 놓여있는 지는 전혀 감을 잡을 수가 없습니다. 또 외부의 환경으로부터 대체로 분리되어 있고요. \u0026lsquo;독립적으로 실행되는 프로세스\u0026rsquo;라는 것이 바로 외부로 부터 지켜지는 \u0026lsquo;내부의 스타워즈 굿즈\u0026rsquo;와 같은 개념 입니다.\n정말 컴퓨터 세계에서 사용하는 화물 컨테이너라고 할 수 있겠죠? 다만, 내부에 좀 컴퓨터 적인 친구들을 담고 있을 뿐이죠. 가령 우분투나 센토스 같은 리눅스 운영체제 이미지 같은 거 말이에요. 컨테이너를 실행(컴퓨터 세상이다보니까 운송하는 대신 실행합니다)하는 외부의 환경이 윈도우 운영체제라도 문제 없습니다. 내부의 물건은 외부로부터 지켜지고 있거든요!\n컨테이너 기술은 가상 머신(Virtual Machine)과 많이 비교되곤 합니다. 둘의 공통점은 가상화 기술을 사용한다는 것 입니다. 가상화는 단일한 물리 하드웨어 시스템에서 여러 시뮬레이션 환경이나 전용 리소스를 생성할 수 있는 기술입니다. 구체적인 건 몰라도, 컨테이너 기술은 가상 머신에 비해 무척 가볍게 실행 됩니다. 가상 머신에서는 하이퍼바이저라는 것을 이용해 새로운 운영체제를 실행해야 하는데, 컨테이너는 그럴 필요가 없습니다. 그렇기에 똑같은 우분투 버전을 설치한다고 했을 때 용량 측면에서도, 실행 속도 측면에서도 꽤나 비교됩니다.\n컨테이너를 활용하는 경우에 대한 예제를 설명 드려볼까요? 저는 학창 시절에 \u0026lsquo;포트란\u0026rsquo;이라는 프로그래밍 언어를 사용했습니다. 포트란의 컴파일러 중 하나인 gfortran은 리눅스 환경에서는 무료로 쉽게 설치가 가능합니다. 하지만 리눅스에 대해 일도 몰랐던 저는 처음엔 윈도우 환경에서 포트란을 사용하고자 했었죠. 하지만 곧 마음을 바꿔 먹어야 했습니다. 윈도우에서 포트란을 사용하는 방법이 아예 없던 것은 아니지만, 리눅스 환경보다는 설치가 좀 더 어려웠고, 무료버전 컴파일러가 깔끔하지도 않았거든요. 저는 결국 리눅스와 친해지기로 결심하고 우분투를 컴퓨터에 설치했는데요. 은행 업무나 아래한글 프로그램 같은 것을 활용하기에 참 힘든 환경이었기에 꽤나 고생했던 기억이 납니다. 그런데 지금와서 생각해보면 쉽게 해결될 문제였습니다. 윈도우 운영체제 위에서 컨테이너 기술을 활용해 리눅스를 구동시켰다면 말이에요. (질문 - 컨테이너를 VM 처럼 써도 되는 걸 까요?)\n또 다른 예시는 데이터베이스 설치입니다. 데이터베이스도 컨테이너 환경으로 쉽게 구동 할 수 있습니다. 사용하지 않을 때는 컨테이너를 내려 마치 컴퓨터에 없는 존재처럼 만들 수도 있지요. 아까 컨테이너 내부는 외부로부터 지켜진다고 하였는데, 실제로 기본적인 설정으로는(네트워크 설정을 따로 해주지 않으면) 외부에서 컨테이너 내부로 통신할 방법이 없습니다. 컨테이너 내부에 독자적인 가상 네트워크만이 설정되기 때문이죠. 그럼 데이터베이스를 사용할 방법이 없게 느껴지시겠지만, 이제 쿠버네티스(혹은 도커)가 이런 부분을 해결해 줄 수 있습니다.\n도커? 쿠버네티스랑 같은 거에요? 도커랑 쿠버네티스는 다른 것입니다. 그러나 뗄 수 없는 사이 입니다.\nDocker라는 영단어는 사전적으로 항만 노동자라는 의미를 가지고 있습니다. 쿠버네티스와 비슷하게 바다를 연상케 하는 단어지요. 저는 위에서 여러번 컨테이너를 \u0026lsquo;실행\u0026rsquo;한다 라는 표현을 사용 했습니다. 도커라는 녀석은 이를 가능케 해주는 오픈 소스 프로젝트 입니다. 쿠버네티스를 사용하기 위해서는 도커와 같은 \u0026lsquo;컨테이너 런타임\u0026rsquo; 기술을 필요로 합니다.\n(정확하게는 도커와 쿠버네티스가 아니라, 컨테이너 런타임과 쿠버네티스는 뗄레야 뗄 수 없는 사이라고 해야겠습니다)\n로고를 한 번 보고 가시죠. 귀엽게 생긴 고래 배가 수 많은 컨테이너를 실고 물 위에 떠 있습니다. 그림이 암시하는 것처럼 사실 쿠버네티스 없이 도커만 있어도 컨테이너 한두 개를 운영하는 것은 문제가 되지 않습니다.\n허나, 도커가 출시된 해는 2013년이고 쿠버네티스보다 1년 정도 빠르게 등장한 기술입니다. 도커가 컨테이너 환경을 이용할 완벽한 기술이라면 쿠버네티스가 등장할 필요가 있었을까요? 쿠버네티스가 뒤늦게 등장했다는 것은 도커만으로 해결할 수 없는 문제가 있지 않을까라는 추론을 가능케 합니다. 네, 도커에는 중대한 문제가 있습니다. 한두 개가 아닌 수많은 컨테이너를 관리하기 힘들다라는 것 입니다.\n아마, 이런 생각을 하실 수 있으실 것 같습니다. 컨테이너를 그렇게 많이 구동 시킬 필요가 있나? 데이터베이스든 운영체제든 아무리 많이 필요하다고 해도 손가락으로 셀 수 있을 정도 아닐까? 이 질문에 대한 답이 바로 MSA(마이크로서비스 아키텍쳐)입니다.\n(다음에 계속)\n","date":"September 11, 2022","hero":"/images/hero/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EA%B0%80%20%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C.png","permalink":"https://kubesy.com/posts/500.-tech_dev/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4-%EA%B8%B0%EB%B3%B8/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EA%B0%80-%EB%AD%90%EC%A7%80/","summary":"\u003cp\u003e22년도에 작성했던, 일반인을 위한 쿠버네티스 소개글입니다\u0026hellip; 배운지 몇달 안 된 상태에서 썼던 글이라 각종 (이상한) 추상적인 표현이 많습니다.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e안녕하세요.\n좋은 기회를 통해 최근 공부하고 있는 IT 기술인 쿠버네티스에 대해 소개 해드리고자 합니다.\u003c/p\u003e\n\u003ch3 id=\"쿠버네티스\"\u003e쿠버네티스?\u003c/h3\u003e\n\u003cp\u003e최근 NHN사의 클라우드 교육을 다녀왔었습니다. 클라우드는 이제 많은 사람이 쉽고 편하게 사용하는 기술이지요? 매킨토시를 쓰거나, 윈도우를 쓸 때 icloud,  OneDrive등의 기능을 쓰시는 분이 많을테고, 구글에서도 구글 드라이브에 자료를 저장하는 등의 경험이 있으실 것 같습니다.  그런 클라우드 시장에서 주목하는 기술 중 하나가 쿠버네티스 입니다.\u003c/p\u003e","tags":null,"title":"쿠버네티스가 뭐지 1"}]